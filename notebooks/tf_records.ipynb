{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3692cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.__version__)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import deepcell\n",
    "# Changed from before due to new placement of Track, concat_tracks\n",
    "from deepcell_tracking.utils import load_trks\n",
    "from deepcell.data.tracking import Track, concat_tracks\n",
    "##############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepcell.utils.data_utils import reshape_movie\n",
    "from deepcell.utils.transform_utils import erode_edges\n",
    "from deepcell.data import split_dataset\n",
    "from deepcell_toolbox.processing import normalize, histogram_normalization\n",
    "\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df81ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_img_dict(file):\n",
    "    f = open(file)\n",
    "    d = json.load(f)\n",
    "    d = {int(k1): {int(k2): {int(k3): v for k3, v in d[k1][k2].items()} for k2, d[k1][k2] in d[k1].items()} for k1, d[k1] in d.items()}\n",
    "    return d\n",
    "def load_img_idx_dict(file):\n",
    "    f = open(file)\n",
    "    d = json.load(f)\n",
    "    d = {int(k): v for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1dd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_good_imgs = load_img_dict('../dataset_pruning/train_appearances_dict.json')\n",
    "train_blank_imgs = load_img_dict('../dataset_pruning/train_blank_dict.json')\n",
    "train_border_imgs = load_img_dict('../dataset_pruning/train_border_dict.json')\n",
    "val_good_imgs = load_img_dict('../dataset_pruning/val_appearances_dict.json')\n",
    "val_blank_imgs = load_img_dict('../dataset_pruning/val_blank_dict.json')\n",
    "val_border_imgs = load_img_dict('../dataset_pruning/val_border_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the images are written to disk one at a time, we can modify the write function to write the image to disk\n",
    "# only when the image is \"good.\" Can pass in the dictionary of good images as an argument. The funciton uses \n",
    "# track.appearances, the NP array, to write the file. Since the dictionary corresponds with the indices of the \n",
    "# array, we can use this to determine which images to add.\n",
    "\n",
    "# Based on this line in the Track class, 'appearances = np.zeros(batch_shape + appearance_shape, dtype='float32')',\n",
    "# it seems the track.appearances object does not have any batch/cells/frames pattern, but we should check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f575ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7426fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ad79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepcell_tracking.trk_io import load_trks\n",
    "from deepcell_tracking.utils import get_max_cells\n",
    "from deepcell.data.tracking import Track\n",
    "# Might want to import this just to get the functions it uses\n",
    "from deepcell.utils.tfrecord_utils import write_tracking_dataset_to_tfr\n",
    "\n",
    "def get_arg_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--data-path',\n",
    "                        default='/training/tracking-nuclear',\n",
    "                        help='Path to the training data.')\n",
    "\n",
    "    parser.add_argument('--appearance-dim', type=int, default=64)\n",
    "    parser.add_argument('--distance-threshold', type=int, default=64)\n",
    "    parser.add_argument('--crop-mode', type=str, default='fixed')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aee4a230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\"create_tracking_example\" in dir(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d633f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.io import serialize_tensor\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import is_sparse\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        # BytesList won't unpack a string from an EagerTensor.\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def create_tracking_example(track_dict):\n",
    "    \"\"\"Create a tf.train.Example for a single item\n",
    "    of a tracking dataset\n",
    "    Args:\n",
    "        track_dict (dict): A dictionary with a single\n",
    "            item of a tracking dataset\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # Define the dictionary of our single example\n",
    "    for key in track_dict:\n",
    "        # WE DON'T NEED TO BOTHER WITH CHECKING FOR SPARSE KEYS (REMOVED THAT)\n",
    "        data[key] = _bytes_feature(serialize_tensor(track_dict[key]))\n",
    "\n",
    "        shapes = track_dict[key].shape\n",
    "\n",
    "        # I DON'T REALLY GET WHAT THIS IS DOING\n",
    "        for i in range(len(shapes)):\n",
    "            shape_string = '{}_shape_{}'.format(key, i)\n",
    "            data[shape_string] = _int64_feature(shapes[i])\n",
    "\n",
    "    # Create an Example, wrapping the single features\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1cb2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tracking_dataset_to_tfr(track,\n",
    "                                  filename,\n",
    "                                  good_imgs,\n",
    "                                  target_max_cells=168,\n",
    "                                  verbose=True):\n",
    "\n",
    "    filename_tfr = filename + '.tfrecord'\n",
    "    filename_csv = filename + '.csv'\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(filename_tfr)\n",
    "\n",
    "    # Get features to add\n",
    "    # WE PROBABLY ONLY CARE ABOUT APP\n",
    "    app = track.appearances\n",
    "\n",
    "    # Pad cells - we need to do this to use validation data\n",
    "    # during training\n",
    "\n",
    "    # TARGET MAX CELLS WILL BE THE MAXIMUM 'CELLS' DIMENSION BETWEEN TRAIN AND VAL,\n",
    "    # AND THE OTHER ONE WILL BE PADDED TO ACHIEVE THAT. I PROBABLY DON'T NEED TO\n",
    "    # PAD ANYTHING, SINCE MY DATA IS IN THE FORMAT (num_imgs, dim, dim, 1), NOT\n",
    "    # (batches, frames, cells, dim, dim, 1).\n",
    "    \n",
    "    # Iterate over all batches\n",
    "    # THIS SHOULD PROBABLY BE THE CELLS THEMSELVES IN MY CASE\n",
    "    for b in range(app.shape[0]):\n",
    "        for f in range(app.shape[1]):\n",
    "            for c in range(app.shape[2]):\n",
    "                if good_imgs[b][c][f] != -1:\n",
    "                    img = app[b, f, c]\n",
    "                    track_dict = {'app': img}\n",
    "\n",
    "                    example = create_tracking_example(track_dict)\n",
    "\n",
    "                    if example is not None:\n",
    "                        writer.write(example.SerializeToString())\n",
    "                        count += 1\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Wrote {count} elements to TFRecord')\n",
    "\n",
    "    # WE'LL WORRY ABOUT THE CSV WRITER FOR METADATA AT THE END, IF NECESSARY\n",
    "    # OKAY WE MIGHT NEED IT TO PARSE THE DATA\n",
    "    # Save dataset metadata\n",
    "    # THIS SHOULD BE OKAY--WE JUST HAVE ONE KEY RATHER THAN A BUNCH, NOW\n",
    "    dataset_keys = track_dict.keys()\n",
    "    dataset_dims = [len(track_dict[k].shape) for k in dataset_keys]\n",
    "\n",
    "    with open(filename_csv, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        rows = [[k, dims] for k, dims in zip(dataset_keys, dataset_dims)]\n",
    "        writer.writerows(rows)\n",
    "        \n",
    "        # SHOULDN'T NEED ROWS FOR adj_shape AND temp_adj_shape, SINCE WE'RE NOT\n",
    "        # WRITING THESE\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b405a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably no reaon to use argument parser--only there because they wanted to run it from the command line\n",
    "args = get_arg_parser().parse_args([])\n",
    "\n",
    "train_trks = load_trks(os.path.join(args.data_path, 'train.trks'))\n",
    "val_trks = load_trks(os.path.join('/training/tracking-nuclear', 'val.trks'))\n",
    "\n",
    "# max_cells = max([get_max_cells(train_trks['y']), get_max_cells(val_trks['y'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33c42eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 27/27 [02:45<00:00,  6.12s/it]\n",
      "100%|███████████████████████████████████████████| 27/27 [04:08<00:00,  9.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 89436 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    val_tracks = Track(tracked_data=val_trks,\n",
    "                   appearance_dim=args.appearance_dim,\n",
    "                   distance_threshold=args.distance_threshold,\n",
    "                   crop_mode=args.crop_mode)\n",
    "\n",
    "    write_tracking_dataset_to_tfr(val_tracks, filename='val', good_imgs=val_good_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0456e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 89436 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    write_tracking_dataset_to_tfr(val_tracks, filename='val', good_imgs=val_good_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6845bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 91/91 [12:54<00:00,  8.52s/it]\n",
      "100%|███████████████████████████████████████████| 91/91 [20:18<00:00, 13.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 383800 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_tracks = Track(tracked_data=train_trks,\n",
    "                   appearance_dim=args.appearance_dim,\n",
    "                   distance_threshold=args.distance_threshold,\n",
    "                   crop_mode=args.crop_mode)\n",
    "\n",
    "    write_tracking_dataset_to_tfr(train_tracks, filename='train', good_imgs=train_good_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61f15825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 383800 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    write_tracking_dataset_to_tfr(train_tracks, filename='train', good_imgs=train_good_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f26c452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepcell.data.tracking.Track"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91cfdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe when we parse, we can return a tuple (not dictionary) with two images (the same) of shape (1, 64, 64, 1)\n",
    "# We probably don't need the CSV file of dimensions, can just put dimensions like the examples do in the Examples\n",
    "def parse_tracking_example(example, dataset_ndims,\n",
    "                           dtype=tf.float32):\n",
    "    \"\"\"Parse a tracking example\n",
    "    Args:\n",
    "        example (tf.train.Example): The tracking example to be parsed\n",
    "        dataset_ndims (dict): Dictionary of dataset metadata\n",
    "        dtype (tf dtype): Dtype of training data\n",
    "    \"\"\"\n",
    "    # WE MIGHT NEED THE METADATA NOW, TO PARSE IT\n",
    "\n",
    "    # WHAT IS THE DIFFERENCE BETWEEN X AND y?\n",
    "    X_names = ['app']\n",
    "\n",
    "    full_name_dict = {'app': 'appearances'}\n",
    "\n",
    "    # Recreate the example structure\n",
    "    data = {}\n",
    "    shape_strings_dict = {}\n",
    "    shapes_dict = {}\n",
    "\n",
    "    for key in dataset_ndims:\n",
    "        if 'shape' in key:\n",
    "            new_key = '_'.join(key.split('_')[0:-1])\n",
    "            shapes_dict[new_key] = dataset_ndims[key]\n",
    "\n",
    "    for key in shapes_dict:\n",
    "        dataset_ndims.pop('{}_shape'.format(key))\n",
    "\n",
    "    for key in dataset_ndims:\n",
    "        # NO SUCH THING AS sparse_names ANYMORE\n",
    "        data[key] = tf.io.FixedLenFeature([], tf.string)\n",
    "\n",
    "        shape_strings = ['{}_shape_{}'.format(key, i)\n",
    "                         for i in range(dataset_ndims[key])]\n",
    "        shape_strings_dict[key] = shape_strings\n",
    "\n",
    "        for ss in shape_strings:\n",
    "            data[ss] = tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "    # Get data\n",
    "    content = tf.io.parse_single_example(example, data)\n",
    "\n",
    "    X_dict = {}\n",
    "\n",
    "    for key in dataset_ndims:\n",
    "\n",
    "        # Get the feature and reshape\n",
    "        # AGAIN NO NEED TO CHECK FOR SPARSENESS\n",
    "        shape = [content[ss] for ss in shape_strings_dict[key]]\n",
    "        value = content[key]\n",
    "        value = tf.io.parse_tensor(value, out_type=dtype)\n",
    "        value = tf.reshape(value, shape=shape)\n",
    "\n",
    "        X_dict[full_name_dict[key]] = value\n",
    "\n",
    "    return X_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "847f4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filename, parse_fn=None, **kwargs):\n",
    "    \"\"\"Get a TFRecord Dataset\n",
    "    Args:\n",
    "        filename (str): The base filename of the dataset to be\n",
    "            loaded. The filetype (e.g., .tfrecord) should not\n",
    "            be included\n",
    "        parse_fn (python function): The function for parsing\n",
    "            tf.train.Example examples in the the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Define tfrecord and csv file\n",
    "    filename_tfrecord = filename + '.tfrecord'\n",
    "    filename_csv = filename + '.csv'\n",
    "\n",
    "    # Load the csv\n",
    "    dataset_ndims = {}\n",
    "    shapes = {}\n",
    "\n",
    "    with open(filename_csv) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if 'shape' in row[0]:\n",
    "                dataset_ndims[row[0]] = [int(i) for i in row[1:]]\n",
    "            else:\n",
    "                dataset_ndims[row[0]] = int(row[1])\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename_tfrecord)\n",
    "\n",
    "    # Pass each feature through the mapping function\n",
    "    def parse_func(example):\n",
    "        return parse_fn(example,\n",
    "                        dataset_ndims=dataset_ndims,\n",
    "                        **kwargs)\n",
    "\n",
    "    dataset = dataset.map(parse_func)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df4c61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filename, parse_fn=None, **kwargs):\n",
    "    \"\"\"Get a TFRecord Dataset\n",
    "    Args:\n",
    "        filename (str): The base filename of the dataset to be\n",
    "            loaded. The filetype (e.g., .tfrecord) should not\n",
    "            be included\n",
    "        parse_fn (python function): The function for parsing\n",
    "            tf.train.Example examples in the the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Define tfrecord and csv file\n",
    "    filename_tfrecord = filename + '.tfrecord'\n",
    "    filename_csv = filename + '.csv'\n",
    "\n",
    "    # Load the csv\n",
    "    dataset_ndims = {}\n",
    "    shapes = {}\n",
    "\n",
    "    with open(filename_csv) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if 'shape' in row[0]:\n",
    "                dataset_ndims[row[0]] = [int(i) for i in row[1:]]\n",
    "            else:\n",
    "                dataset_ndims[row[0]] = int(row[1])\n",
    "\n",
    "    # Create the dataset\n",
    "    # MIGHT NEED TO DO from_tensor_slices AND REPEAT THE DATA\n",
    "    dataset = tf.data.TFRecordDataset(filename_tfrecord)\n",
    "\n",
    "    # Pass each feature through the mapping function\n",
    "    def parse_func(example):\n",
    "        return parse_fn(example,\n",
    "                        dataset_ndims=dataset_ndims,\n",
    "                        **kwargs)\n",
    "\n",
    "    dataset = dataset.map(parse_func)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cbfef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset('train', parse_fn=parse_tracking_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b664965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_dataset('val', parse_fn=parse_tracking_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fcb8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset.take(3):\n",
    "    print(sample['input_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c129e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989632bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20ec0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96f7442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    \n",
    "    def __init__(self, dim_z, kl_weight, learning_rate):\n",
    "        # change dim from (28, 28, 1)\n",
    "        self.dim_x = (64, 64, 1)\n",
    "        self.dim_z = dim_z\n",
    "        self.kl_weight = kl_weight\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Sequential API encoder\n",
    "    def encoder_z(self):\n",
    "        # define prior distribution for the code, which is an isotropic Gaussian\n",
    "        prior = tfd.Independent(tfd.Normal(loc=tf.zeros(self.dim_z), scale=1.), \n",
    "                                reinterpreted_batch_ndims=1)\n",
    "        # build layers argument for tfk.Sequential()\n",
    "        input_shape = self.dim_x\n",
    "        layers = [tfkl.InputLayer(input_shape=input_shape)]\n",
    "        layers.append(tfkl.Conv2D(filters=32, kernel_size=3, strides=(2,2), \n",
    "                                  padding='valid', activation='relu'))\n",
    "        layers.append(tfkl.Conv2D(filters=64, kernel_size=3, strides=(2,2), \n",
    "                                  padding='valid', activation='relu'))\n",
    "        layers.append(tfkl.Flatten())\n",
    "        # the following two lines set the output to be a probabilistic distribution\n",
    "        layers.append(tfkl.Dense(tfpl.IndependentNormal.params_size(self.dim_z), \n",
    "                                 activation=None, name='z_params'))\n",
    "        layers.append(tfpl.IndependentNormal(self.dim_z, \n",
    "            convert_to_tensor_fn=tfd.Distribution.sample, \n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=self.kl_weight), \n",
    "            name='z_layer'))\n",
    "        return tfk.Sequential(layers, name='encoder')\n",
    "    \n",
    "    # Sequential API decoder\n",
    "    def decoder_x(self):\n",
    "        layers = [tfkl.InputLayer(input_shape=self.dim_z)]\n",
    "        # probably 7 before since 28/2/2 = 7, so changing to 32/2/2 = 8\n",
    "        layers.append(tfkl.Dense(16*16*32, activation=None))\n",
    "        layers.append(tfkl.Reshape((16,16,32)))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=64, kernel_size=3, strides=2, \n",
    "                                           padding='same', activation='relu'))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=32, kernel_size=3, strides=2, \n",
    "                                           padding='same', activation='relu'))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=1, kernel_size=3, strides=1, \n",
    "                                           padding='same'))\n",
    "        layers.append(tfkl.Flatten())\n",
    "        # note that here we don't need \n",
    "        # `tfkl.Dense(tfpl.IndependentBernoulli.params_size(self.dim_x))` because \n",
    "        # we've restored the desired input shape with the last Conv2DTranspose layer\n",
    "        layers.append(tfkl.Dense(tfpl.IndependentNormal.params_size(self.dim_x), \n",
    "                                 activation=None, name='x_params'))\n",
    "        layers.append(tfpl.IndependentNormal(self.dim_x,\n",
    "            name='x_layer'))\n",
    "        return tfk.Sequential(layers, name='decoder')\n",
    "    \n",
    "    def build_vae_keras_model(self):\n",
    "        x_input = tfk.Input(shape=self.dim_x)\n",
    "        encoder = self.encoder_z()\n",
    "        decoder = self.decoder_x()\n",
    "        z = encoder(x_input)\n",
    "\n",
    "        # compile VAE model\n",
    "        model = tfk.Model(inputs=x_input, outputs=decoder(z))\n",
    "        model.compile(loss=negative_log_likelihood, \n",
    "                      optimizer=tfk.optimizers.Adam(self.learning_rate))\n",
    "        return model\n",
    "\n",
    "# the negative of log-likelihood for probabilistic output\n",
    "negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16f347e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(1024, 1, 1e-3)\n",
    "AE = vae.build_vae_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c08371b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 183, in assert_input_compatibility\n        raise ValueError(f'Missing data for input \"{name}\". '\n\n    ValueError: Missing data for input \"input_7\". You passed a data dictionary with keys ['input_1']. Expected the following keys: ['input_7']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/first_64_64\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m train_callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[1;32m     11\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;43;03m#     steps_per_epoch=steps_per_epoch,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;43;03m#     validation_steps=validation_steps,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_callbacks\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 183, in assert_input_compatibility\n        raise ValueError(f'Missing data for input \"{name}\". '\n\n    ValueError: Missing data for input \"input_7\". You passed a data dictionary with keys ['input_1']. Expected the following keys: ['input_7']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.optimizers import RectifiedAdam as RAdam\n",
    "from deepcell import train_utils\n",
    "\n",
    "# steps_per_epoch = 3838\n",
    "# validation_steps = 895\n",
    "n_epochs = 1\n",
    "model_path = '../models/first_64_64'\n",
    "\n",
    "train_callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "      \n",
    "        monitor='val_loss', factor=0.5, verbose=1,\n",
    "        patience=3, min_lr=1e-7),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path, monitor='val_loss',\n",
    "        save_best_only=True, verbose=1,\n",
    "        save_weights_only=True)\n",
    "]\n",
    "\n",
    "loss_history = AE.fit(\n",
    "    train_dataset,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_dataset,\n",
    "#     validation_steps=validation_steps,\n",
    "    epochs=n_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=train_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, what is the form of the .tfrecord file?\n",
    "# I think we need an image, recon pair (two keys) for each feature, like they did image, label in the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "432f4972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_tracks.appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc98837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 71, 277, 64, 64, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tracks.appearances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
