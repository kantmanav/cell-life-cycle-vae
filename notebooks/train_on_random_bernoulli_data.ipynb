{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18928ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3138c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_MNIST:\n",
    "    \n",
    "    def __init__(self, dim_z, kl_weight, learning_rate):\n",
    "        # change dim from (28, 28, 1)\n",
    "        self.dim_x = (32, 32, 1)\n",
    "        self.dim_z = dim_z\n",
    "        self.kl_weight = kl_weight\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Sequential API encoder\n",
    "    def encoder_z(self):\n",
    "        # define prior distribution for the code, which is an isotropic Gaussian\n",
    "        prior = tfd.Independent(tfd.Normal(loc=tf.zeros(self.dim_z), scale=1.), \n",
    "                                reinterpreted_batch_ndims=1)\n",
    "        # build layers argument for tfk.Sequential()\n",
    "        input_shape = self.dim_x\n",
    "        layers = [tfkl.InputLayer(input_shape=input_shape)]\n",
    "        layers.append(tfkl.Conv2D(filters=32, kernel_size=3, strides=(2,2), \n",
    "                                  padding='valid', activation='relu'))\n",
    "        layers.append(tfkl.Conv2D(filters=64, kernel_size=3, strides=(2,2), \n",
    "                                  padding='valid', activation='relu'))\n",
    "        layers.append(tfkl.Flatten())\n",
    "        # the following two lines set the output to be a probabilistic distribution\n",
    "        layers.append(tfkl.Dense(tfpl.IndependentNormal.params_size(self.dim_z), \n",
    "                                 activation=None, name='z_params'))\n",
    "        layers.append(tfpl.IndependentNormal(self.dim_z, \n",
    "            convert_to_tensor_fn=tfd.Distribution.sample, \n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=self.kl_weight), \n",
    "            name='z_layer'))\n",
    "        return tfk.Sequential(layers, name='encoder')\n",
    "    \n",
    "    # Sequential API decoder\n",
    "    def decoder_x(self):\n",
    "        layers = [tfkl.InputLayer(input_shape=self.dim_z)]\n",
    "        # probably 7 before since 28/2/2 = 7, so changing to 32/2/2 = 8\n",
    "        layers.append(tfkl.Dense(8*8*32, activation=None))\n",
    "        layers.append(tfkl.Reshape((8,8,32)))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=64, kernel_size=3, strides=2, \n",
    "                                           padding='same', activation='relu'))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=32, kernel_size=3, strides=2, \n",
    "                                           padding='same', activation='relu'))\n",
    "        layers.append(tfkl.Conv2DTranspose(filters=1, kernel_size=3, strides=1, \n",
    "                                           padding='same'))\n",
    "        layers.append(tfkl.Flatten(name='x_params'))\n",
    "        # note that here we don't need \n",
    "        # `tfkl.Dense(tfpl.IndependentBernoulli.params_size(self.dim_x))` because \n",
    "        # we've restored the desired input shape with the last Conv2DTranspose layer\n",
    "        layers.append(tfpl.IndependentBernoulli(self.dim_x, name='x_layer'))\n",
    "        return tfk.Sequential(layers, name='decoder')\n",
    "    \n",
    "    def build_vae_keras_model(self):\n",
    "        x_input = tfk.Input(shape=self.dim_x)\n",
    "        encoder = self.encoder_z()\n",
    "        decoder = self.decoder_x()\n",
    "        z = encoder(x_input)\n",
    "\n",
    "        # compile VAE model\n",
    "        model = tfk.Model(inputs=x_input, outputs=decoder(z))\n",
    "        model.compile(loss=negative_log_likelihood, \n",
    "                      optimizer=tfk.optimizers.Adam(self.learning_rate))\n",
    "        return model\n",
    "\n",
    "# the negative of log-likelihood for probabilistic output\n",
    "negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b1abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.__version__)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import deepcell\n",
    "# Changed from before due to new placement of Track, concat_tracks\n",
    "from deepcell_tracking.utils import load_trks\n",
    "from deepcell.data.tracking import Track, concat_tracks\n",
    "##############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepcell.utils.data_utils import reshape_movie\n",
    "from deepcell.utils.transform_utils import erode_edges\n",
    "from deepcell.data import split_dataset\n",
    "from deepcell_toolbox.processing import normalize, histogram_normalization\n",
    "\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f245ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a binary dataset on which to train the model. It should be of the same format as the above dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_MNIST(1024, 1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca479e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 1, 32, 32, 1), dtype=tf.int64, name=None), TensorSpec(shape=(None, 1, 32, 32, 1), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a real problem with somewhat large data (wasn't able to allocate space)\n",
    "\n",
    "train_data = np.random.choice([0, 1], size=(3000, 1, 32, 32, 1), p=[0.5, 0.5])\n",
    "val_data = np.random.choice([0, 1], size=(1000, 1, 32, 32, 1), p=[0.5, 0.5])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_data))\n",
    "train_ds.batch(10)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_data, val_data))\n",
    "val_ds.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d87ff425",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = vae.build_vae_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f90a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7102312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 22:43:57.573872: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 28s 9ms/step - loss: 721.2941 - val_loss: 717.6370\n"
     ]
    }
   ],
   "source": [
    "# steps_per_epoch = 2048\n",
    "# validation_steps = 100\n",
    "n_epochs = 1\n",
    "\n",
    "# train_callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\n",
    "#         model_path, monitor='val_loss',\n",
    "#         save_best_only=True, verbose=1,\n",
    "#         save_weights_only=False),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_loss', factor=0.5, verbose=1,\n",
    "#         patience=3, min_lr=1e-7)\n",
    "# ]\n",
    "\n",
    "loss_history = AE.fit(\n",
    "    train_ds,\n",
    "#    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "#    validation_steps=validation_steps,\n",
    "    epochs=n_epochs,\n",
    "    verbose=1,\n",
    "#    callbacks=train_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da34d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
